%!TEX root = ../summaries.tex

\chapter{AI Governance, and careers in alignment research}


\section{Careers in alignment}

\url{https://docs.google.com/document/d/1iFszDulgpu1aZcq_aYFG7Nmcr5zgOhaeSwavOMk1akw/edit#heading=h.4whc9v22p7tb}

\begin{itemize}
    \item Part 1: Excerpt from Gleave's Careers in Beneficial AI Research.
    \begin{itemize}
        \item Is Technical AI Research Right for You?
        \begin{itemize}
            \item Technical alignment research one of most high-impact careers for someone with technical background.
            \item Also consider AI strategy and policy.
            \begin{itemize}
                \item Benefit from people with technical background.
            \end{itemize}
            \item Also consider biorisk, global warming, etc.
        \end{itemize}
        \item Skills within Technical AI Research
        \begin{itemize}
            \item Four main skill sets.
            \begin{enumerate}[label=(\Alph*)]
                \item\label{item:se; careers} Software engineering.
                \item\label{item:ml imp; careers} ML implementation.
                \item\label{item:ml rea; careers} ML research direction.
                \item\label{item:tr; careers} Theory research.
            \end{enumerate}
            \item Approximate mapping onto job titles.
            \begin{itemize}
                \item Research engineers: lots of \ref{item:se; careers}, some of \ref{item:ml imp; careers}.
                \item Deep learning researchers: \ref{item:ml imp; careers} and \ref{item:ml rea; careers}.
                \item Other ML researchers: mostly \ref{item:ml rea; careers}, some \ref{item:tr; careers}.
                \item Theory: \ref{item:tr; careers}.
            \end{itemize}
            \item Progress in beneficial AI bottlenecked on researchers and research engineers.
        \end{itemize}
    \end{itemize}
\end{itemize}


\section{AI Governance: Opportunity and Theory of Impact}

\url{https://forum.effectivealtruism.org/posts/42reWndoTEhFqu6T8/ai-governance-opportunity-and-theory-of-impact}

\begin{itemize}
    \item Primarily aimed at longtermist perspective: long-term risks and opportunities.
    \item Unlike other longtermist work, focus on more conventional AI scenarios.
\end{itemize}


\subsection{Contemporary Policy Challenges}

\begin{itemize}
    \item AI increasingly applied in important domains with societal impact.
    \item Effect seen in \textquote{international tax law, competition/antitrust policy, innovation policy, and national security motivated controls on trade and investment}.
    \item To work in these areas, need to understand both specific policy area and technical AI details.
    \item Important to create community working across these policy areas, are there are interacting phenomena.
\end{itemize}


\subsection{Long-term Risks and Opportunities}

\begin{itemize}
    \item Superintelligence Perspective.
    \begin{itemize}
        \item Superintelligent AI will pose profound risks and opportunities.
        \item Pose threat to human control which dwarfs other natural or anthropogenic risks.
        \item Managing AI competition.
        \begin{itemize}
            \item Problems exasperated if actors perceive themselves to be in an intense winner-take-all race.
            \item Motivated to cut corners.
        \end{itemize}
        \item \emph{Constitution design}.
        \begin{itemize}
            \item How developer should institutionalise control over intelligence and share its bounty.
        \end{itemize}
        \item \emph{Governance and AI safety interact}.
        \begin{itemize}
            \item Sometimes substitutes, sometimes complements.
            \item Insights into global risks could accelerate AI safety work.
            \item AI safety work could enable new policies.
        \end{itemize}
    \end{itemize}
    \item Ecology and GPT Perspectives.
    \begin{itemize}
        \item Superintelligence perspective not only route to risk.
        \item Criticised for making strong assumptions about nature of advanced AI systems.
        \item \emph{AI ecology perspective}
        \begin{itemize}
            \item Diverse global ecology of systems.
            \item Degree of agency of these systems varies.
            \item Superintelligence in narrow domains.
            \item May be more likely than general superintelligence.
            \item May be easier to do safely.
        \end{itemize}
        \item \emph{General purpose technology perspective}.
        \begin{itemize}
            \item Don't need to emphasise agent-like AI or even powerful AI.
            \item Instead focus on ways even mundane AI could transform many parts of society.
            \item Examples.
            \begin{itemize}
                \item Dramatically reduce labour share and increase inequality.
                \item Reduce cost of surveillance and repression.
                \item Make global markets more oligopolistic.
                \item Alter logic of wealth production.
                \item Shift military power.
                \item Undermine nuclear stability.
            \end{itemize}
            \item Most close to that expressed by economists and policy makers.
        \end{itemize}
        \item Three perspectives not mutually exclusive.
        \begin{itemize}
            \item E.g.\@ GPT perspective help shape environment in which superintelligence emerges.
        \end{itemize}
    \end{itemize}
    \item Misuse Risks, Accident Risks, Structural Risks.
    \begin{itemize}
        \item Many analyses of risk (especially superintelligence perspective) adopt lenses of misuse or accident.
        \begin{itemize}
            \item Misuse: person uses AI system in unethical way.
            \item Accident: unanticipated consequences of using system.
            \item Place responsibility with actor who could have prevented risk.
            \item Typically, opportunity for safety intervention causally close to harm.
        \end{itemize}
        \item Ecology and GPT perspectives emphasise broader lens of structural risks.
        \begin{itemize}
            \item No single actor responsible to risks.
            \item Arise due to structural dynamics.
            \item Analogy: climate change risk from invention of combustion engine.
        \end{itemize}
        \item More superintelligence perspective implies more investment in cutting edge of AI and AI safety.
        \begin{itemize}
            \item Focus on groups most likely to develop superintelligence.
            \item Ensure they have best culture, values, etc.
        \end{itemize}
        \item More ecology and GPT perspective implies more need to understand safety and governance broadly.
        \begin{itemize}
            \item Risk distributed over broad range of scenarios.
            \item Risk-reduction opportunities also broadly distributed.
            \item More likely that existing social structures will shape risks.
            \item Greater need for collaboration, across broad collection of actors.
        \end{itemize}
        \item Existential-risk-concerned people often prioritise superintelligence perspective.
        \begin{itemize}
            \item Describes concrete and causally close ways humans to lose all power.
            \item Ecology and GPT perspectives also useful for examining existential risks.
            \item They can also illuminate risk factors.
        \end{itemize}
    \end{itemize}
\end{itemize}


\subsection{Concrete Pathways to Existential Risk}

\begin{itemize}
    \item Concrete ways in which ecology and GPT perspectives lead to existential risk.
    \item Nuclear Instability.
    \begin{itemize}
        \item Risk of nuclear war increased with relatively mundane improvements in \textquote{sensor technology, cyberweapons, and autonomous weapons}.
    \end{itemize}
    \item Power Transitions, Uncertainty, and Turbulence.
    \begin{itemize}
        \item Technology can change key parameters underlying global bargains.
        \item Lead to power transitions.
        \item Shift offence-defence balance, making war more tempting, or amplifying fear of being attacked.
        \item Lead to great turbulence, which can lead to breakdown of social structures.
        \item All of this can increase risk of systemic war, or weaken humanity's ability to work collectively.
    \end{itemize}
    \item Inequality, Labour Displacement, Authoritarianism.
    \begin{itemize}
        \item World becomes more unequal, undemocratic and hostile to human labour.
        \item Processes catalysed by AI.
        \begin{itemize}
            \item Winner-take-all markets.
            \item Displacement of labour.
            \item Authoritarian surveillance and control.
        \end{itemize}
        \item Could lead to robust totalitarianism.
        \begin{itemize}
            \item Lock-in of bad values.
            \item Increase other existential risks from weakening of government.
        \end{itemize}
        \item Epistemic Security.
        \begin{itemize}
            \item Use of AI for mass psychological manipulation in democracies.
            \item Reduce ability for mass deliberation.
            \item Lower chances that advanced democracies shape AI advancement.
        \end{itemize}
        \item Value Erosion through Competition.
        \begin{itemize}
            \item Race to develop AI can lead to cutting corners.
            \item Generalises: trade-offs between human values and performance.
            \begin{itemize}
                \item Non-monopolistic markets.
                \item Privacy.
                \item Relative equality.
            \end{itemize}
            \item Erosion of these values.
            \item Competitive dynamics can lead to lock-ins of bad values.
        \end{itemize}
    \end{itemize}
\end{itemize}


\subsection{Prioritization and Theory of Impact}

\begin{itemize}
    \item Allocation of investments depends on nature of problem.
    \item Author sees value in all perspectives.
    \item Advocates broad portfolio of investments.
    \item Still needs prioritisation: what directions to invest in.
    \item \emph{Asset-decision model of research impact}: provide assets to help people who eventually make impactful decisions.
    \begin{itemize}
        \item Technical solutions.
        \item Strategies.
        \item Shared perception of risks.
        \item More cooperative worldview.
        \item Competent advisors.
        \item Credibility, authority, connections for these advisors.
    \end{itemize}
    \item Different perspectives on which assets more important.
    \begin{itemize}
        \item \emph{Product model of research}.
        \begin{itemize}
            \item Value of funding research finding out about specific, important questions.
            \item Good when problems well-defined.
            \item Widely-held.
            \item Perpetuated by researchers.
            \item Author: this substantially underestimates importance of AI safety and governance research.
        \end{itemize}
        \item \emph{Field building model of research}.
        \begin{itemize}
            \item Majority of value comes from ways funding supports growing and improving field.
            \item Focuses on other assets.
            \begin{itemize}
                \item Getting people with diverse experience.
                \item Improving AI governance researchers' competence in relevant areas.
                \item Giving intellectual authority and prestige to those with thoughtful perspectives on long-term AI.
                \item Growing field.
                \item Boosting junior researchers.
            \end{itemize}
        \end{itemize}
    \end{itemize}
    \item Attaining outcomes of field building model may be best achieved by focusing on producing good research projects.
    \begin{itemize}
        \item Similarly to why governments fund basic research: \textquote{the byproduct national benefits that it produces, such as nationally available expertise, talent networks, spinoff businesses, educational and career opportunities, and national absorptive capacity for cutting edge science}.
        \item Considering the problem of international control of AI, important to build up a field, so that it's ready when the time comes.
        \item This can be done by considering concrete research questions: even though the results may not be directly useful, the competence/research networks/etc.\@ built up by doing it will be.
    \end{itemize}
    \item Analogy: international control of nuclear weapons.
    \begin{itemize}
        \item Though theorised about in advance, actual implementation depended on so many inpredictable factors.
        \item Important to have body of experts, ready and empowered to engage with current situation.
        \item AI problem similar, but requires even more diverse portfolio, because there is more uncertainty.
    \end{itemize}
\end{itemize}


\section{Cooperation, conflict and transformative AI: sections 1 \& 2}

\subsection{Introduction}

\begin{itemize}
    \item Transformative artificial intelligence: \textquote{AI that precipitates a transition comparable to (or more significant than) the agricultural or industrial revolution}.
    \item Research agenda: preventing catastrophic cooperation failures between TAI-enabled actors.
    \item Risks from TAI great enough to motivate research now, despite uncertainties around timeline.
    \item Cooperation failures can occur between agent-like systems, or between human actors assisted by powerful but narrow AIs.
    \item TAI likely to present new challenges compared to existing research on cooperation in other fields.
    \begin{itemize}
        \item Because of more powerful actors.
        \item Powerful actors can significantly increase capabilities with successful bargaining.
        \item Qualitative changes in nature of multi-agent systems, stemming from nature of machine intelligence.
        \begin{itemize}
            \item Ability to make credible commitments.
            \item Ability to self-modify.
            \item Ability to model other agents.
        \end{itemize}
    \end{itemize}
    \item Cooperation failure: models and examples.
    \begin{itemize}
        \item \emph{Social dilemma}: Game in which mutual cooperation is better for everyone, but individual rationality may lead to defection.
        \item \emph{Nash equilibrium}.
        \item Social dilemmas have been used to model international politics cooperation failures.
        \begin{itemize}
            \item E.g.\@ arms race as Prisoner's Dilemma.
        \end{itemize}
        \item Usually better to model using games with incomplete information.
        \item Analyses of war: bargaining model of warm / crisis bargaining.
        \item Three standard hypotheses for why states go to war.
        \begin{itemize}
            \item Credibility: can't credibly commit to terms of peace treaty.
            \item Incomplete information: different private info wrt chances of winning war; incentive to be deceitful about this.
            \item Indivisible stakes: things of value can't be shared between parties.
        \end{itemize}
        \item A different cooperation failure: extortion.
        \begin{itemize}
            \item Harms extortee.
            \item Also harms extorter, because of the inefficiencies of making threats (like war).
        \end{itemize}
        \item Counterargument to `indivisible stakes': simulated conflict.
        \begin{itemize}
            \item Allocated full stakes to party based on probability of winning war Pareto-dominates.
            \item Relies on e.g.\@ access to mutually trusted war-simulator.
        \end{itemize}
        \item Game theoretic methods not fully suitable, since TAI-enabled agents not necessarily modelled as rational agents.
    \end{itemize}
    \item Outline of the agenda.
    \begin{itemize}
        \item Section 2: AI strategy and governance.
        \begin{itemize}
            \item Risks from cooperation failures depends on strategic landscape when TAI deployed.
            \begin{itemize}
                \item Uni-polar vs.\@ multi-polar.
                \item Offensive vs.\@ defensive capabilities.
            \end{itemize}
            \item Want to understand this landscape.
            \begin{itemize}
                \item Figure out which levers prevent catastrophic cooperation failures.
            \end{itemize}
            \item This is quite theoretical: how does it translate to TAI governance.
        \end{itemize}
        \item Section 3: Credibility.
        \begin{itemize}
            \item Agents' ability to self-modify, and the ability to inspect internal workings of others, changes nature of credible commitments.
            \item Calls for application of existing game theory and decision theory to new kinds of agents, and the development of new theory.
        \end{itemize}
        \item Section 4: Peaceful bargaining mechanisms.
        \begin{itemize}
            \item \emph{Peaceful bargaining mechanism}: system which doesn't lead to conflict, and in which each player in incentivised to play strategy not leading to destructive conflict.
        \end{itemize}
        \item Section 5: Contemporary AI architectures.
        \begin{itemize}
            \item Multi-agent AI increasingly studied by ML researchers.
            \item Unexplored avenues remain.
            \begin{itemize}
                \item Using agents' transparency to one another.
                \item Implications of multi-agent training schemes.
                \item Decision making procedures implicitly implemented by RL schemes.
            \end{itemize}
        \end{itemize}
        \item Section 6: Humans in the loop.
        \begin{itemize}
            \item Either human-controlled AI or AI which seeks to respect human preferences.
            \item Behavioural game theory for human-in-the-loop AIs.
            \item Interaction between humans and AIs.
        \end{itemize}
        \item Section 7: Foundations of rational agency.
        \begin{itemize}
            \item Various open problems relevant to TAI.
        \end{itemize}
    \end{itemize}
\end{itemize}


\subsection{AI strategy and governance}

\begin{itemize}
    \item Polarity and transition scenarios.
    \begin{itemize}
        \item Prima facie preferable if TAI results in unipolar outcome: single actor develops TAI.
        \item Analysis likely less simple, judging by literature on different power distributions in international relations.
        \item Wants.
        \begin{itemize}
            \item Understand likelihoods of various scenarios.
            \item Relative safety of these.
            \item Feasibility of policy directions to steer towards better power distributions.
        \end{itemize}
        \item Questions.
        \begin{itemize}
            \item Should we expect rapid jumps in AI capabilities?
            \begin{itemize}
                \item Makes unipolar more likely.
                \item So far progress gradual.
            \end{itemize}
            \item Which distributions of power give lower risks of catastrophic cooperation failures?
            \item Which are the levers to shift towards these distributions, which don't have major downsides?
        \end{itemize}
    \end{itemize}
    \item Commitment and transparency.
    \begin{itemize}
        \item Strategic implications of ability to commit.
        \item \emph{Commitment races}: both parties want to make certain commitments (e.g.\@ to carry out threat if demands not met) as soon as possible, to improve bargaining position.
        \begin{itemize}
            \item Like Chicken.
            \item Dangerous situation.
            \item Transparency double-edged sword.
            \begin{itemize}
                \item Can spot in advance e.g.\@ build-up of doomsday devices.
                \item Can make more credible commitments.
            \end{itemize}
            \item What policy encourages the development of transparent TAI systems?
        \end{itemize}
        \item In human societies, greater abilities to make credible commitments facilitated large gains in trade.
        \begin{itemize}
            \item What features of increased credibility promote better outcomes?
            \begin{itemize}
                \item How would societal outcomes change with unlimited ability to make credible commitments?
                \item Other societies where laws and norms allow(ed) this?
            \end{itemize}
            \item How have technologies changed bargaining in the past?
            \item Open-source game theory: idealised form of mutual auditing.
            \begin{itemize}
                \item Historical cases of mutual auditing?
            \end{itemize}
            \item Costs from increased commitment ability?
        \end{itemize}
    \end{itemize}
    \item AI misalignment scenarios.
    \begin{itemize}
        \item Few detailed descriptions of future with misaligned AI.
        \item Misalignments likely to be near-misses, or more extreme departures from our values?
        \item Will human-aligned systems be able to cooperate with misaligned?
        \item Likelihood of deployment of outright misaligned AI vs. gradual misalignment?
        \item In the above, what is landscape of cooperation failures?
    \end{itemize}
    \item Other directions.
    \begin{itemize}
        \item Offence-defence theory: risk and nature of conflict depends on relative efficacy of offensive and defensive capabilities.
        \begin{itemize}
            \item Technological progressive key factor in change of these.
            \item Would like to be able to predict strategy landscape when TAI deployed, to predict nature of resulting changes in offence-defence.
            \item E.g.\@ cybersecurity.
        \end{itemize}
        \item Lessons drawn from past cases of cooperation failure.
        \begin{itemize}
            \item How policies have influenced these risks.
            \item Examples of case studies.
            \begin{itemize}
                \item Nuclear deterrence.
                \item Ransomware.
                \item Economics of hostage taking.
                \item Extortion rackets.
            \end{itemize}
            \item Things which could be investigated.
            \begin{itemize}
                \item Costs to threateners.
                \item Gains to threateners.
                \item Damage to third parties.
                \item Factors affecting agents' vulnerability to threats.
                \item Existing efforts to combat extortionists.
            \end{itemize}
            \item Unclear how effective will be with TAI systems.
            \item Could be quite effective with human-in-the loop systems.
        \end{itemize}
        \item Analysis of how similar instances of formal research have influenced actual policy.
        \begin{itemize}
            \item Application of game theory to geopolitics.
            \item Application of cryptography to computer security.
            \item Application of formal verification.
        \end{itemize}
    \end{itemize}
    \item Potential downsides of research on cooperation failures.
    \begin{itemize}
        \item May actually increase risks from compellent threats.
        \item Na√Øve application of theories of completely rational agents to humans may do more harm than good.
        \item Important to also research these potential downsides.
    \end{itemize}
\end{itemize}


\section{The Semiconductor Supply Chain: Assessing National Competitiveness}

\subsection{Executive Summary}

\begin{itemize}
    \item Computer chips produced using complex supply changes.
    \item Understanding these essential for formulating policy to ensure competitiveness and security.
    \item Supply chains often quite opaque.
    \item Broken down chains into key components relevant to policymakers.
    \item United States and allies lead global supply chain; China lags.
    \begin{itemize}
        \item US contributes 39\% value.
        \item US allies contribute another 53\%.
        \item US and allies have competitive advantages in nearly every segment.
        \item China contributes 6\%, but is developing quickly and could restructure chains to its benefit.
    \end{itemize}
    \item Supply chains at high level.
    \begin{itemize}
        \item Research and development.
        \begin{itemize}
            \item Underpins all production and inputs.
        \end{itemize}
        \item Production.
        \begin{itemize}
            \item Design.
            \item Manufacturing.
            \item ATP: assembly, testing and packaging.
        \end{itemize}
        \item Production inputs.
        \begin{itemize}
            \item SME: semiconductor manufacturing equipment.
            \item Materials.
            \item EDA: electronic design automation software.
            \item Core IP: intellectual property related to chip designs.
        \end{itemize}
        \item Distribution for end use.
    \end{itemize}
    \item Highest value and most technologically complex parts.
    \begin{itemize}
        \item Design and fabrication segments of production.
        \item SME.
    \end{itemize}
    \item EDA and core IP small by critical and of great expense.
    \item ATP labour intensive; lowest barrier to entry.
    \item Country specialisms.
    \begin{itemize}
        \item US.
        \begin{itemize}
            \item Dominates R\&D.
            \item Strong capabilities across all segments.
            \item Lacks firms in some key subsectors (e.g.\@ photolithography tools, most complex and expensive part of SME).
        \end{itemize}
        \item South Korea.
        \begin{itemize}
            \item Specialises in all production steps.
            \item Produces significant amount of materials.
            \item Some SME.
        \end{itemize}
        \item Taiwan.
        \begin{itemize}
            \item Dominant in most advanced manufacturing and ATP.
            \item Produces some SME.
        \end{itemize}
        \item Japan.
        \begin{itemize}
            \item Specialises in SME and materials.
            \item Produces many older technology chips.
        \end{itemize}
        \item Europe (especially the Netherlands, the United Kingdom, and Germany).
        \begin{itemize}
            \item Specialises in SME (especially photolithography tools), materials and core IP.
        \end{itemize}
        \item China.
        \begin{itemize}
            \item Strongest in ATP and raw materials.
            \item Progressing in design and manufacturing with some state support.
            \item Struggles in production inputs: SME, EDA, core IP and some core materials.
        \end{itemize}
    \end{itemize}
\end{itemize}


\section{The Global AI Talent Tracker}

\url{https://macropolo.org/digital-projects/the-global-ai-talent-tracker/}

\begin{itemize}
    \item Applying AI requires several key inputs.
    \begin{itemize}
        \item Research and engineering talent.
        \item Data.
        \item Computational power.
        \item Healthy innovation ecosystem.
    \end{itemize}
    \item Talent one of most important and easy to quantify.
    \item Article: assesses global balance and flow of AI talent by looking at researchers with papers accepted to NeurIPS 2019.
    \begin{itemize}
        \item Regarded as most important AI conference.
        \item 15,920 researchers submitted 6,614.
        \item 21.6\% acceptance rate.
        \item Proxy for top-tier researchers.
    \end{itemize}
    \item Key takeaways.
    \begin{itemize}
        \item US has large lead over other countries.
        \begin{itemize}
            \item Nearly 60\% of top-tier researchers working in US.
            \item Attracts international talent: 59\% of researchers working in US did undergrad in different country.
        \end{itemize}
        \item China largest source of top-tier researchers.
        \begin{itemize}
            \item 29\% did undergrad in China.
            \item Most (56\%) go on to live and work in US.
        \end{itemize}
        \item 53\% of top-tier researchers are immigrants or foreign nationals.
    \end{itemize}
    \item Other insights noticed from data presentations.
    \begin{itemize}
        \item 64\% of papers had coauthors from different countries.
        \item 88\% of Chinese AI PhD students work in US afterwards.
        \item 85\% of non-Chinese AI PhD students work in US afterwards.
        \item Over a third of the most elite researchers received their undergrad in the US.
        \item Two-thirds of the most elite researchers work in the US.
        \item Google is by far the top institution publishing papers, followed by Stanford University, Carnegie Mellon University, MIT and Microsoft.
        \item Oxford is 8th.
    \end{itemize}
\end{itemize}