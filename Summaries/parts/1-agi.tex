%!TEX root = ../summaries.tex

\chapter{Artificial General Intelligence}

\section{Four Background Claims}

\noindent\url{https://intelligence.org/2015/07/24/four-background-claims/}

\begin{itemize}
    \item Claim 1: Humans have a general problem solving ability.
    \begin{itemize}
        \item General across domains.
        \item Some have argued that we only have disparate, specific modules.
    \end{itemize}
    \item Claim 2: An AI system could be much more intelligent than humans.
    \begin{itemize}
        \item Something special about brains?
        \begin{itemize}
            \item Brains are physical systems; according to the Church-Turing thesis, a compute should be able to replicate.
            \item Even if there is a special human feature, what really matters is general problem-solving ability.
        \end{itemize}
        \item Algorithms for general intelligence to complex to program?
        \begin{itemize}
            \item Evolutionary evidence: general intelligence evolved rapidly in humans.
            \item Relative intelligence of dolphins suggests building blocks already present in mouse-like common ancestor. Simulating mouse brain seems quite plausible.
        \end{itemize}
        \item Humans already at or near peak intelligence?
        \begin{itemize}
            \item Would be surprising if humans were perfected reasoners.
            \item Imagine increasing human processing power.
            \item Real bottleneck being able to receive data from physical experiments? Unlikely: many interesting experiments can be sped up.
        \end{itemize}
    \end{itemize}
    \item Claim 3: Super-intelligent AI systems, if built, will shape the future.
    \begin{itemize}
        \item Intelligent beings shape environment to further their goals.
        \item AI system would not be able to defeat humanity as a whole — environment too competitive?
        \begin{itemize}
            \item Selfish actors only integrate into economy as long as it benefits them.
            \item Historically, more technologically advanced civilisations have dominated less.
            \item A number of social and technological advancements seem possible, but have not yet been developed.
            \item Humans coordinate poorly and slowly.
            \item This suggests potential to gain technological advantage.
        \end{itemize}
    \end{itemize}
    \item Intelligent systems won't be beneficial by default.
    \begin{itemize}
        \item To achieve beneficiality, need to solve many technical challenges.
        \item Humans have become more peaceful as we have become more intelligent — will machines learn to act more in accordance with our values?
        \begin{itemize}
            \item Based on misunderstanding of machine intelligence.
        \end{itemize}
    \end{itemize}
\end{itemize}


\section{AGI Safety From First Principles}

\begin{itemize}
    \item Second species argument
    \begin{itemize}
        \item We will build super-intelligent machines.
        \item They will be autonomous agents perusing large-scale goals.
        \item The goals will be mis-aligned with ours.
        \item The development of these systems will lead us to lose control of our future.
    \end{itemize}
    \item Uses examples from ML. Some arguments carry over to systems developed using other techniques.
\end{itemize}


\subsection{Superintelligence}

\begin{itemize}
    \item Intelligence: ability to do well on a broad range of tasks.
    \item Task-based approach to intelligence: specifically optimised for a range of tasks.
    \begin{itemize}
        \item How we use electricity: need to design specific ways to use it for each task.
        \item Current reinforcement learning.
    \end{itemize}
    \item Generalisation-based approach to intelligence: understand new tasks with little or no specific training, generalising from past experience.
    \begin{itemize}
        \item GPT-2, GPT-3.
        \item Meta-learning.
        \item Human learning.
        \begin{itemize}
            \item Learn many specific skills throughout childhood.
            \item These skills are not the same as the economically useful ones we need in adulthood.
            \item Abstraction is key.
        \end{itemize}
    \end{itemize}
    \item Really, it's a spectrum.
    \item Task-based approach likely to yield better results sooner in areas where we have lots of data.
    \begin{itemize}
        \item E.g. self-driving cars, medicine, law, mathematics.
    \end{itemize}
    \item Generalisation-based approach likely to be needed for other areas.
    \begin{itemize}
        \item  E.g. being a CEO, which required a range of skills and has comparatively little data available.
        \item Likely strategy: train AI on other area where we have lots of data, so that it develops necessary cognitive skills.
    \end{itemize}
    \item Potential obstacle to success of generalisation-based approach: could be that in past specific features of ancestral environment or    brains necessary for development of general intelligence.
    \begin{itemize}
        \item E.g. `social arms race' necessary for development of social intelligence.
        \item Likely that any such feature could be simulated.
    \end{itemize}    
\end{itemize}