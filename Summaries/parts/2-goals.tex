%!TEX root = ../summaries.tex

\chapter{Goals and alignment}

\section{Specification gaming: the flip side of AI ingenuity}

\url{https://deepmindsafetyresearch.medium.com/specification-gaming-the-flip-side-of-ai-ingenuity-c85bdb0deeb4}

\begin{itemize}
    \item Specification gaming can be a good thing, if the goal is correctly specified.
    \item More powerful learning more likely to do specification gaming.
    \item Desirability of novel solutions lies on a spectrum.
    \item Causes of specification gaming.
    \begin{itemize}
        \item Poor reward shaping: extra rewards on the way to the final one.
        \item Poor final outcome specification.
        \begin{itemize}
            \item Can use human feedback to learn reward function.
            \item This itself may suffer specification gaming: agent performing grasping task learned to fool human exploiting optical illusion.
        \end{itemize}
        \item Simulator bugs.
        \begin{itemize}
            \item About failure of abstraction exploited by agent.
            \item Analogously, real-world traffic optimiser assumes that there aren't bugs in software controlling traffic which can be exploited.
        \end{itemize}
        \item Reward tampering: changing mechanism by which it gets rewarded in real world.
        \begin{itemize}
            \item E.g.\@ by manipulating humans.
        \end{itemize}
    \end{itemize}
    \item At least three challenges.
    \begin{itemize}
        \item Faithfully capture human concept of task.
        \item Avoid making mistakes in implicit assumptions about domain.
        \item Avoid reward tampering.
    \end{itemize}
\end{itemize}


\section{Risks from learned optimization}

\url{https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB/p/FkgsxrGf3QxhfLWHG}

\begin{itemize}
    \item \emph{Mesa-optimiser}: learned model which is itself an optimiser.
    \item When will this happen?
    \item What will the objective be?
    \item Whether is system is an optimiser is a property of its internal structure.
    \item \emph{Base optimiser}: algo which produced the model.
    \item \emph{Behavioural objective}: objective which seems to be optimised by system.
    \item \emph{Outer alignment problem}: eliminating the gap between the base objective and the intended goal of the the programmers.
    \item \emph{Inner alignment problem}: eliminating the gap between the base objective and the mesa-objective.
    \begin{itemize}
        \item Mesa-optimiser may perform well on training data, but the mesa-objective may differ from the base objective out of distribution.
    \end{itemize}
\end{itemize}


\section{Superintelligence, Chapter 7: The superintelligent will}

\begin{itemize}
    \item \emph{The orthogonality thesis}: \textquote{Intelligence and final goals are orthogonal: more or less any level of intelligence could in principle be combined with more or less any final goal.}
    \item \emph{The instrumental convergence thesis}: \textquote{Several instrumental values can be identified which are convergent in the sense that their attainment would increase the chances of the agentâ€™s goal being realized for a wide range of final goals and a wide range of situations, implying that these instrumental values are likely to be pursued by a broad spectrum of situated intelligent agents.}
    \begin{itemize}
        \item Self-preservation.
        \item Goal-content integrity.
        \begin{itemize}
            \item May be less strong if there are factors directly interfacing with the goal specifications.
        \end{itemize}
        \item Cognitive enhancement.
        \begin{itemize}
            \item Under certain circumstances, some forms of enhancement may be undesirable.
        \end{itemize}
        \item Technological perfection.
        \item Resource acquisition
    \end{itemize}
\end{itemize}